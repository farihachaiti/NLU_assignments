{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac90bcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\farih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal:\u001b[0m 3914; \u001b[1mTrain:\u001b[0m 3523; \u001b[1mTest:\u001b[0m 391\n",
      "\u001b[1mTagging with NgramTagger\u001b[0m\n",
      "\u001b[1mINPUT:\u001b[0m ['First', 'of', 'America', 'said', '0', 'some', 'of', 'the', 'managers', 'will', 'take', 'other', 'jobs', 'with', 'First', 'of', 'America', '.']\n",
      "\u001b[1mTAG:\u001b[0m [('First', 'NOUN'), ('of', 'ADP'), ('America', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('some', 'DET'), ('of', 'ADP'), ('the', 'DET'), ('managers', 'NOUN'), ('will', 'VERB'), ('take', 'VERB'), ('other', 'ADJ'), ('jobs', 'NOUN'), ('with', 'ADP'), ('First', 'NOUN'), ('of', 'ADP'), ('America', 'NOUN'), ('.', '.')]\n",
      "\u001b[1mAccuracy of NgramTagger:\u001b[0m 0.8471\n",
      "\u001b[1mTagging with Spacy\u001b[0m\n",
      "\u001b[1mINPUT:\u001b[0m ['First', 'of', 'America', 'said', '0', 'some', 'of', 'the', 'managers', 'will', 'take', 'other', 'jobs', 'with', 'First', 'of', 'America', '.']\n",
      "\u001b[1mREFERENCE:\u001b[0m [('First', 'NOUN'), ('of', 'ADP'), ('America', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('some', 'DET'), ('of', 'ADP'), ('the', 'DET'), ('managers', 'NOUN'), ('will', 'VERB'), ('take', 'VERB'), ('other', 'ADJ'), ('jobs', 'NOUN'), ('with', 'ADP'), ('First', 'NOUN'), ('of', 'ADP'), ('America', 'NOUN'), ('.', '.')]\n",
      "\u001b[1mTAG:\u001b[0m [('First', 'ADV'), ('of', 'ADP'), ('America', 'PROPN'), ('said', 'VERB'), ('0', 'PUNCT'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('managers', 'NOUN'), ('will', 'AUX'), ('take', 'VERB'), ('other', 'ADJ'), ('jobs', 'NOUN'), ('with', 'ADP'), ('First', 'PROPN'), ('of', 'ADP'), ('America', 'PROPN'), ('.', 'PUNCT')]\n",
      "\u001b[1mAccuracy of Spacy:\u001b[0m 0.5556\n"
     ]
    }
   ],
   "source": [
    "#import nltk.NgramTagger as ngramT\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import DefaultTagger \n",
    "import spacy\n",
    "import math\n",
    "import en_core_web_sm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Prepare Training & Test Splits as 90%/10%\n",
    "\n",
    "\n",
    "nltk.download('treebank')\n",
    "\n",
    "total_size = len(treebank.tagged_sents())\n",
    "train_indx = math.ceil(total_size * 0.9)\n",
    "trn_data = treebank.tagged_sents(tagset='universal')[:train_indx]\n",
    "tst_data = treebank.tagged_sents(tagset='universal')[train_indx:]\n",
    "\n",
    "print(\"\\033[1mTotal:\\033[0m {}; \\033[1mTrain:\\033[0m {}; \\033[1mTest:\\033[0m {}\".format(total_size, len(trn_data), len(tst_data)))\n",
    "\n",
    "print(\"\\033[1mTagging with NgramTagger\\033[0m\")\n",
    "\n",
    "backoff = DefaultTagger('NN')\n",
    "ngramTagger = nltk.NgramTagger(1,train=trn_data,cutoff=1,backoff=backoff)\n",
    "\n",
    "def nlp_accuracy(reference, test):\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    return sum(x == y for x, y in zip(reference, test)) / len(test)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[train_indx:]:\n",
    "    print(\"\\033[1mINPUT:\\033[0m {}\".format(s))\n",
    "    print(\"\\033[1mTAG:\\033[0m {}\".format(ngramTagger.tag(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = ngramTagger.accuracy(tst_data)\n",
    "\n",
    "print(\"\\033[1mAccuracy of NgramTagger:\\033[0m {:6.4f}\".format(accuracy))\n",
    "\n",
    "print(\"\\033[1mTagging with Spacy\\033[0m\")\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "for id_sent,sent in enumerate(treebank.sents()[train_indx:]):\n",
    "    doc = nlp(\" \".join(sent))\n",
    "    break\n",
    "\n",
    "test = [(t.text, t.pos_) for t in doc]\n",
    "\n",
    "for s in treebank.sents()[train_indx:]:\n",
    "    print(\"\\033[1mINPUT:\\033[0m {}\".format(s))\n",
    "    reference = ngramTagger.tag(s)\n",
    "    break\n",
    "    \n",
    "print(\"\\033[1mREFERENCE:\\033[0m {}\".format(reference))\n",
    "print(\"\\033[1mTAG:\\033[0m {}\".format(test))\n",
    "\n",
    "mapping_spacy_to_NLTK = {\n",
    "    \"ADJ\": \"ADJ\",\n",
    "    \"ADP\": \"ADP\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"AUX\": \"VERB\",\n",
    "    \"CCONJ\": \"CONJ\",\n",
    "    \"DET\": \"DET\",\n",
    "    \"INTJ\": \"X\",\n",
    "    \"NOUN\": \"NOUN\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PRT\",\n",
    "    \"PRON\": \"PRON\",\n",
    "    \"PROPN\": \"NOUN\",\n",
    "    \"PUNCT\": \".\",\n",
    "    \"SCONJ\": \"CONJ\",\n",
    "    \"SYM\": \"X\",\n",
    "    \"VERB\": \"VERB\",\n",
    "    \"X\": \"X\"\n",
    "}\n",
    "\n",
    "accuracy = nlp_accuracy(reference, test)\n",
    "print(\"\\033[1mAccuracy of Spacy:\\033[0m {:6.4f}\".format(accuracy))\n",
    "\n",
    "# tokens\n",
    "#print([t.text for t in doc])\n",
    "\n",
    "# Fine grained POS-tags\n",
    "#print([t.tag_ for t in doc])\n",
    "\n",
    "# Coarse POS-tags (from Universal POS Tag set)\n",
    "#print([t.pos_ for t in doc])\n",
    "\n",
    "#print (classification_report(correct_labels, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
